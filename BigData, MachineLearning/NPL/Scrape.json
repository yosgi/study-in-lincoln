{
    "cells": [
      {
        "cell_type": "markdown",
        "source": [
          "# Scraping and Summarizing News"
        ],
        "metadata": {
          "id": "Pq1pSlxYuSUG"
        }
      },
      {
        "cell_type": "markdown",
        "metadata": {
          "id": "qBaZML6Qyd2l"
        },
        "source": [
          "# 1. Install and Import Baseline Dependencies"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "collapsed": true,
          "id": "yqW4lGXryd2r"
        },
        "outputs": [],
        "source": [
          "!pip install transformers"
        ]
      },
      {
        "cell_type": "code",
        "source": [
          "!pip install sentencepiece"
        ],
        "metadata": {
          "id": "1g5mA3xOy3iu"
        },
        "execution_count": null,
        "outputs": []
      },
      {
        "cell_type": "code",
        "execution_count": 3,
        "metadata": {
          "id": "P9O7cl5xyd2w"
        },
        "outputs": [],
        "source": [
          "from transformers import PegasusForConditionalGeneration, AutoTokenizer\n",
          "from bs4 import BeautifulSoup\n",
          "import requests"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {
          "id": "w8mgnoAqyd2x"
        },
        "source": [
          "# 2. Setup Summarization Model"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "kMOnlOZfyd2x"
        },
        "outputs": [],
        "source": [
          "model_name = \"human-centered-summarization/financial-summarization-pegasus\"\n",
          "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
          "model = PegasusForConditionalGeneration.from_pretrained(model_name)"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {
          "id": "rdCIS9iKyd2y"
        },
        "source": [
          "# 3. Summarize a Single Article"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 7,
        "metadata": {
          "id": "GPt5o7l4yd2y"
        },
        "outputs": [],
        "source": [
          "url = \"https://nz.yahoo.com/news/no-donald-trump-isn-t-195944759.html\"\n",
          "r = requests.get(url)\n",
          "soup = BeautifulSoup(r.text, 'html.parser')\n",
          "paragraphs = soup.find_all('p')"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "q8n10FaFyd2z"
        },
        "outputs": [],
        "source": [
          "paragraphs[0].text"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 9,
        "metadata": {
          "id": "w0LINDvxyd20"
        },
        "outputs": [],
        "source": [
          "text = [paragraph.text for paragraph in paragraphs]\n",
          "words = ' '.join(text).split(' ')[:400]\n",
          "ARTICLE = ' '.join(words)"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "t8euROXcyd22"
        },
        "outputs": [],
        "source": [
          "ARTICLE"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 11,
        "metadata": {
          "id": "EAzToIZxyd23"
        },
        "outputs": [],
        "source": [
          "input_ids = tokenizer.encode(ARTICLE, return_tensors='pt')\n",
          "output = model.generate(input_ids, max_length=55, num_beams=5, early_stopping=True)\n",
          "summary = tokenizer.decode(output[0], skip_special_tokens=True)"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "bIX1OrNjyd23"
        },
        "outputs": [],
        "source": [
          "summary"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {
          "id": "FzKdtSLhyd26"
        },
        "source": [
          "# 4. Building a News and Sentiment Pipeline"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 26,
        "metadata": {
          "id": "xtPcsBVByd26"
        },
        "outputs": [],
        "source": [
          "#monitored_tickers = ['TSLA', 'BTC']\n",
          "monitored_tickers = ['BTC']"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {
          "id": "_JwnKkkWyd26"
        },
        "source": [
          "## 4.1. Search for Stock News using Google and Yahoo Finance"
        ]
      },
      {
        "cell_type": "markdown",
        "source": [
          "Google search: yahoo finance {}, and click News."
        ],
        "metadata": {
          "id": "LVX4Fn5OWDzt"
        }
      },
      {
        "cell_type": "code",
        "execution_count": 27,
        "metadata": {
          "id": "42Gq3Xx6yd28"
        },
        "outputs": [],
        "source": [
          "def search_for_stock_news_urls(ticker):\n",
          "    search_url = \"https://www.google.com/search?q=yahoo+finance+{}&tbm=nws\".format(ticker)\n",
          "    r = requests.get(search_url)\n",
          "    soup = BeautifulSoup(r.text, 'html.parser')\n",
          "    atags = soup.find_all('a')\n",
          "    hrefs = [link['href'] for link in atags]\n",
          "    return hrefs"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "yatCT_uOyd29"
        },
        "outputs": [],
        "source": [
          "raw_urls = {ticker:search_for_stock_news_urls(ticker) for ticker in monitored_tickers}\n",
          "raw_urls"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "uca0YzXAyd2_"
        },
        "outputs": [],
        "source": [
          "raw_urls['BTC']"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {
          "id": "6jMPDlpuyd3A"
        },
        "source": [
          "## 4.2. Strip out unwanted URLs"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 30,
        "metadata": {
          "id": "avZZQEAPyd3B"
        },
        "outputs": [],
        "source": [
          "import re"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 31,
        "metadata": {
          "id": "uxdtk63ayd3B"
        },
        "outputs": [],
        "source": [
          "exclude_list = ['maps', 'policies', 'preferences', 'accounts', 'support']"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 32,
        "metadata": {
          "id": "L4W41W7pyd3H"
        },
        "outputs": [],
        "source": [
          "def strip_unwanted_urls(urls, exclude_list):\n",
          "    val = []\n",
          "    for url in urls:\n",
          "        if 'https://' in url and not any(exclude_word in url for exclude_word in exclude_list):\n",
          "            res = re.findall(r'(https?://\\S+)', url)[0].split('&')[0]\n",
          "            val.append(res)\n",
          "    return list(set(val))"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "ijrLt_nWyd3I"
        },
        "outputs": [],
        "source": [
          "cleaned_urls = {ticker:strip_unwanted_urls(raw_urls[ticker], exclude_list) for ticker in monitored_tickers}\n",
          "cleaned_urls"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {
          "id": "B8VvNoHmyd3I"
        },
        "source": [
          "## 4.3. Search and Scrape Cleaned URLs"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 34,
        "metadata": {
          "id": "nclJhgNyyd3J"
        },
        "outputs": [],
        "source": [
          "def scrape_and_process(URLs):\n",
          "    ARTICLES = []\n",
          "    for url in URLs:\n",
          "        r = requests.get(url)\n",
          "        soup = BeautifulSoup(r.text, 'html.parser')\n",
          "        paragraphs = soup.find_all('p')\n",
          "        text = [paragraph.text for paragraph in paragraphs]\n",
          "        words = ' '.join(text).split(' ')[:350]\n",
          "        ARTICLE = ' '.join(words)\n",
          "        ARTICLES.append(ARTICLE)\n",
          "    return ARTICLES"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "PZ3cqYCCyd3J"
        },
        "outputs": [],
        "source": [
          "articles = {ticker:scrape_and_process(cleaned_urls[ticker]) for ticker in monitored_tickers}\n",
          "articles"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {
          "id": "my4mVw1cyd3J"
        },
        "source": [
          "## 4.4. Summarise all Articles"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 36,
        "metadata": {
          "id": "GTcOLbKEyd3K"
        },
        "outputs": [],
        "source": [
          "def summarize(articles):\n",
          "    summaries = []\n",
          "    for article in articles:\n",
          "        input_ids = tokenizer.encode(article, return_tensors='pt', max_length=55, truncation=True)\n",
          "        output = model.generate(input_ids, max_length=55, num_beams=5, early_stopping=True)\n",
          "        summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
          "        summaries.append(summary)\n",
          "    return summaries"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "collapsed": true,
          "id": "WWq9426lyd3K"
        },
        "outputs": [],
        "source": [
          "summaries = {ticker:summarize(articles[ticker]) for ticker in monitored_tickers}\n",
          "summaries"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {
          "id": "03w7WgU8yd3L"
        },
        "source": [
          "# 5. Adding Sentiment Analysis"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "4nTvO-yfyd3L"
        },
        "outputs": [],
        "source": [
          "from transformers import pipeline\n",
          "sentiment = pipeline('sentiment-analysis')"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "rOCLHVxzyd3L"
        },
        "outputs": [],
        "source": [
          "sentiment(summaries['BTC'])"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "CLM41iAQyd3M"
        },
        "outputs": [],
        "source": [
          "scores = {ticker:sentiment(summaries[ticker]) for ticker in monitored_tickers}\n",
          "scores"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {
          "id": "7CojreEjyd3Q"
        },
        "source": [
          "# 6. Exporting Results to CSV"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "collapsed": true,
          "id": "fPMNPHHWyd3R"
        },
        "outputs": [],
        "source": [
          "summaries"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "collapsed": true,
          "id": "ixl0Opsnyd3R"
        },
        "outputs": [],
        "source": [
          "scores"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "collapsed": true,
          "id": "1BmtEsnDyd3R"
        },
        "outputs": [],
        "source": [
          "cleaned_urls"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "Phd_dw2Lyd3R"
        },
        "outputs": [],
        "source": [
          "range(len(summaries['BTC']))"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "id": "2hoTjbLgyd3S"
        },
        "outputs": [],
        "source": [
          "summaries['BTC'][3]"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 48,
        "metadata": {
          "id": "j4RJalzNyd3S"
        },
        "outputs": [],
        "source": [
          "def create_output_array(summaries, scores, urls):\n",
          "    output = []\n",
          "    for ticker in monitored_tickers:\n",
          "        for counter in range(len(summaries[ticker])):\n",
          "            output_this = [\n",
          "                ticker,\n",
          "                summaries[ticker][counter],\n",
          "                scores[ticker][counter]['label'],\n",
          "                scores[ticker][counter]['score'],\n",
          "                urls[ticker][counter]\n",
          "            ]\n",
          "            output.append(output_this)\n",
          "    return output"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "collapsed": true,
          "id": "06ofeShDyd3S"
        },
        "outputs": [],
        "source": [
          "final_output = create_output_array(summaries, scores, cleaned_urls)\n",
          "final_output"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 50,
        "metadata": {
          "id": "3f-gIJgRyd3T"
        },
        "outputs": [],
        "source": [
          "final_output.insert(0, ['Ticker', 'Summary', 'Label', 'Confidence', 'URL'])"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {
          "collapsed": true,
          "id": "aCbvQU3Ayd3T"
        },
        "outputs": [],
        "source": [
          "final_output"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": 52,
        "metadata": {
          "id": "qjyDb8TKyd3T"
        },
        "outputs": [],
        "source": [
          "import csv\n",
          "with open('articlesummaries.csv', mode='w', newline='') as f:\n",
          "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
          "    csv_writer.writerows(final_output)"
        ]
      },
      {
        "cell_type": "markdown",
        "source": [
          "Download **articlesummaries.csv** from the folder icon (📁) in the left panel."
        ],
        "metadata": {
          "id": "c9JyxKxOU2kJ"
        }
      },
      {
        "cell_type": "markdown",
        "source": [
          "##END"
        ],
        "metadata": {
          "id": "NZ-S-NYuUttr"
        }
      }
    ],
    "metadata": {
      "kernelspec": {
        "display_name": "Python 3",
        "language": "python",
        "name": "python3"
      },
      "language_info": {
        "codemirror_mode": {
          "name": "ipython",
          "version": 3
        },
        "file_extension": ".py",
        "mimetype": "text/x-python",
        "name": "python",
        "nbconvert_exporter": "python",
        "pygments_lexer": "ipython3",
        "version": "3.7.3"
      },
      "colab": {
        "provenance": [],
        "collapsed_sections": [
          "qBaZML6Qyd2l",
          "w8mgnoAqyd2x",
          "rdCIS9iKyd2y",
          "FzKdtSLhyd26",
          "_JwnKkkWyd26",
          "6jMPDlpuyd3A",
          "B8VvNoHmyd3I",
          "my4mVw1cyd3J",
          "03w7WgU8yd3L",
          "7CojreEjyd3Q"
        ]
      }
    },
    "nbformat": 4,
    "nbformat_minor": 0
  }